---
title: "Final Project"
author: "Amuan, Loredo, Salinas, & Tamayo"
date: "2023-12-24"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(rvest)
library(dplyr)
library(polite)
library(stringr)

url <- "https://www.airlinequality.com/airport-reviews/istanbul-airport/?sortby=post_date%3ADesc&pagesize=100"

session <- bow(url, user_agent = "Educational Purposes")
session
```

```{r}
library(rvest)
library(stringr)


title <- scrape(session) %>%
  html_nodes("div.text_content") %>%
  html_text()

onehun <- str_replace_all(title, "[\r\n]" , "")

head(onehun)
```

```{r}
url2 <- "https://www.airlinequality.com/airport-reviews/istanbul-airport/page/2/?sortby=post_date%3ADesc&pagesize=100"

session2 <- bow(url2, user_agent = "Educational Purposes")
session2
```

```{r}

library(rvest)
library(stringr)

title2 <- scrape(session2) %>%
  html_nodes("div.text_content") %>%
  html_text()

twohund <- str_replace_all(title2, "[\r\n]" , "")

head(twohund)
```

```{r}
url3 <- "https://www.airlinequality.com/airport-reviews/istanbul-airport/page/3/?sortby=post_date%3ADesc&pagesize=100"

session3 <- bow(url3, user_agent = "Educational Purposes")
session3
```

```{r}
library(rvest)
library(stringr)

title3 <- scrape(session3) %>%
  html_nodes("div.text_content") %>%
  html_text()


threehun <- str_replace_all(title3, "[\r\n]" , "")

head(threehun)
```


```{r}
library(rvest)
library(stringr)

# Initialize
threerev <- character(0)

for (i in 1:3) {

  url <- paste0("https://www.airlinequality.com/airport-reviews/istanbul-airport/page/", i, "/?sortby=post_date%3ADesc&pagesize=100")
  

  session <- bow(url, user_agent = "Educational Purposes")
  
  title <- scrape(session) %>%
    html_nodes("div.text_content") %>%
    html_text()
  
  #Removing \n\r
  clean_title <- str_replace_all(title, "[\r\n]", "")
  
  threerev <- c(threerev, clean_title)
}


```

```{r}
library(openxlsx)


data <- data.frame(Reviews = threerev)
filename <- "Reviews.xlsx" 

write.xlsx(data, filename)

```

```{r}
library(sentimentr)
 
threerev <- character(0)
sentiments <- data.frame()

for (i in 1:3) {
 
  url <- paste0("https://www.airlinequality.com/airport-reviews/istanbul-airport/page/", i, "/?sortby=post_date%3ADesc&pagesize=100")
  

  session <- bow(url, user_agent = "Educational Purposes")
  
  title <- scrape(session) %>%
    html_nodes("div.text_content") %>%
    html_text()
  
 
  cleantitle <- str_replace_all(title, "[\r\n]", "")
  threerev <- c(threerev, cleantitle)
  
  sentiment <- sentiment_by(cleantitle, by = "text")
  sentiments <- rbind(sentiments, sentiment)
}


sentimentAnalysis <- cbind(Reviews = threerev, Sentiments = sentiments)

#View(sentimentAnalysis)
```


```{r}

library(tm)
library(wordcloud)


all_reviews <- c(clean_title, title2, title3)
all_text <- paste(all_reviews, collapse = " ")


corpus <- Corpus(VectorSource(all_text))


corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers) 
corpus <- tm_map(corpus, removeWords, stopwords("english")) 
corpus <- tm_map(corpus, stripWhitespace) 


dtm <- DocumentTermMatrix(corpus)
word_freq <- sort(colSums(as.matrix(dtm)))


wordcloud(words = names(word_freq), freq = word_freq, min.freq = 5,
          max.words = 100, colors = brewer.pal(8, "Dark2"))  

```

The word cloud showcases the most commonly used words in the reviews for Istanbul Airport. The bigger the word appears in the cloud, the more frequently it's mentioned in the reviews it can be negative or positive. This quick visual gives a peek into what people talk about the most when discussing the airport, offering a snapshot of the key topics or feelings shared in those reviews.

